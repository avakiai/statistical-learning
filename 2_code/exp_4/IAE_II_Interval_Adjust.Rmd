---
title: "Interval_Adjust_Task"
author: "Ava Kiai"
date: "4/15/2020"
output: pdf_document
---

```{r}
rm(list=ls()) # clear workspace
# load(".RData") # load saved workspace image for this file

# Directories
setwd(dirname(rstudioapi::getSourceEditorContext()$path))

# Data Path
data_path <- 'C:/Users/Ava/Desktop/Experiments/statistical_learning/1_data/exp_4/interval_adjust_data/dj_test_data'
data_path_save <- 'C:/Users/Ava/Desktop/Experiments/statistical_learning/1_data/exp_4'
# Code Path
code_path <- 'C:/Users/Ava/Desktop/Experiments/statistical_learning/2_code/exp_4'
# Results Path
res_path <- 'C:/Users/Ava/Desktop/Experiments/statistical_learning/3_results/exp_4'

```

# Initialize
```{r message=FALSE, warning=FALSE}
# Init.


# latex font
library(extrafont)
  #font_import(paths="C:/Users/Ava/AppData/Local/Microsoft/Windows/Fonts", pattern = "lmroman*", prompt = T) # only the first time
  loadfonts(device = "win")
  par(family="LM Roman 10")

# basics
library(tidyverse)
# library(reshape2)
# library(ggplot2)
# library(ggsignif)
# library(ggpubr)
# library(gplots)
# 
# # stats
# library(lme4)
# library(multcomp) 
# library(emmeans)
# library(car)
# 
# # advanced plotting & stats  
# library(forcats)
# library(effects)
# library(lsr) 
# library(pwr)
# library(RcppRoll) # for rolling means

# colors
library("wesanderson")
# Note: 
# Blocks colored as Paired from RColorBrewer
# Target Positions as Dark 2 & Pastel 2
# Words 1-4 as set from Grand Budapest
word_pal <- wes_palette("GrandBudapest2",4)

# Load

# Some stuffs for summary stats

source('C:/Users/Ava/Desktop/Experiments/statistical_learning/2_code/summarySE.R')
source('C:/Users/Ava/Desktop/Experiments/statistical_learning/2_code/R_rainclouds.R')
data_files <- list.files(path = data_path, pattern = ".txt")

# Global Plotting Params
w = 6
h = 3

library(dplyr)
```

# Load Data
```{r message=FALSE, warning=FALSE}
for (i in 1:length(data_files)) {
  skip_rows <- which(grepl("Block",readLines(file.path(data_path, data_files[i]))))-1
  curr_data <- read.table(file.path(data_path, data_files[i]),header=TRUE,skip=skip_rows,fill=TRUE)
      if (grepl("End_Time",tail(curr_data$Block,n=1))) {curr_data <- curr_data[-nrow(curr_data),]} 
  curr_data <- plyr::rename(curr_data, c("Sequence" = "Session"))
  session_name <- ifelse(grepl("struct",data_files[i]),"struct","rand")
  curr_data$Session <- rep(session_name,length(curr_data$Session))
  subj_name <- substr(data_files[i], start = 1, stop = 5)
  curr_data <- add_column(curr_data,Subject=rep(subj_name,nrow(curr_data)),.before=TRUE)
  if (i == 1) {raw_dial_data <- mutate_all(curr_data, as.character) # new as of 20/4/20
  } else {raw_dial_data <- bind_rows(mutate_all(raw_dial_data, as.character),mutate_all(curr_data, as.character))} } # ibid.

raw_dial_data <- raw_dial_data %>%
  mutate(Subject = as.factor(Subject), 
         Block = as.numeric(Block),
         Trial = as.numeric(Trial),
         Session = as.factor(Session),
         Syll = as.factor(Syll),
         Dial = as.factor(Dial)) %>%
   mutate_if(is.character,as.numeric)
  # sapply(raw_dial_data,typeof)
  # sapply(raw_dial_data,class)

# Global Vars
n_subjs_dial <- length(unique(raw_dial_data$Subject))
subj_IDs_dial <- unique(raw_dial_data$Subject)

# on to the next... 
wrangle_dial_data <- raw_dial_data

# Sanity Stats
summary(wrangle_dial_data) 
```

# 0 - PREPROCESSING 
```{r Wrangle Data, eval=FALSE, include=FALSE}
# Add Condition Order Column
subjs_SR <- sort(c("s1911","n1906","m0207","h0502","h1209","s0310","t0506","b0704","s2205","s1302"))
n_subjs_SR <- length(subjs_SR)
subjs_RS <- sort(c("a2012","m2208","a2605","m1105","s2609","w2804","b2707","s2502","f0511","s1504"))
n_subjs_RS <- length(subjs_RS)

wrangle_dial_data1 <- wrangle_dial_data %>% mutate(Cond_Order = 0) 
wrangle_dial_data1$Cond_Order[which(wrangle_dial_data1$Subject %in% subjs_SR)] = "struct-rand"
wrangle_dial_data1$Cond_Order[which(wrangle_dial_data1$Subject %in% subjs_RS)] = "rand-struct"

# Add Word Tag Column
wrangle_dial_data1 <- wrangle_dial_data1 %>% mutate(Word = 0) 
words <- list(`1` = c("nu","ga","di"),
              `2` = c("ro","ki","se"),
              `3` = c("mi","po","la"),
              `4` = c("za","be","tu"))
wrangle_dial_data1 <- wrangle_dial_data1 %>% 
  mutate(
    Word = case_when(Session=="struct" & Syll %in% words$`1` ~ 1,
              Session=="struct" & Syll %in% words$`2` ~ 2,
              Session=="struct"& Syll %in% words$`3` ~ 3,
              Session=="struct" & Syll%in% words$`4` ~ 4,
              TRUE ~ NA_real_)) %>%   # Randoms have only NA in the Word column
  mutate(Word = as.factor(Word))

# Add Position Column
wrangle_dial_data1 <- wrangle_dial_data1 %>% mutate(Position = 0) 
positions <- list(`1` = c("nu","ro","mi","za"),
              `2` = c("ga","ki","po","be"),
              `3` = c("di","se","la","tu"))
wrangle_dial_data1 <- wrangle_dial_data1 %>% 
  mutate(
    Position = case_when(Session=="struct" & Syll %in% positions$`1` ~ 1,
              Session=="struct" & Syll %in% positions$`2` ~ 2,
              Session=="struct"& Syll %in% positions$`3` ~ 3,
              TRUE ~ NA_real_)) %>%  
  mutate(Position = as.factor(Position))

# Reorder
wrangle_dial_data2 <- wrangle_dial_data1[c(1,2,3,4,5,13:15,6:12)]
```

When Position == 1, Gap == 1 (between A and B), when == 2, Gap == 2 (between B and C), when == 3, Gap == 3 (between C and A').

To assign positions to the random trials, match the position order of the corresponding trial, and repeat until the trial runs out. E.g. Struct:Block1:Trial1 == Positions(1,3,2) --> Rand:Block1:Trial1 = Positions(1,3,2).

## a. Assign Positions to Struct, Rand
```{r}
# check a matrix summarizing the orders, to view in a glance if there's a roughly even distribution of starting positions (1,2,3)
check <- data.frame("subj" = factor(), "blk" = double(), "trl" = double(), "ord" = integer())

for (curr_subj in subj_IDs_dial) {
  for (curr_blk in unique(wrangle_dial_data2$Block)) {
    for (curr_trl in unique(wrangle_dial_data2$Trial)) {
        curr_subset <- wrangle_dial_data2 %>%    dplyr::filter(Subject==curr_subj,Block==curr_blk,Trial==curr_trl)
        if( all(c("struct","rand") %in% unique(curr_subset$Session)) ) {
          pos_order <- curr_subset %>% dplyr::filter(Session=="struct") %>% pull(Position) %>% .[1:3]
          rand_pos <- rep_len(pos_order,length(which(curr_subset$Session=="rand")))
          wrangle_dial_data2$Position[which(wrangle_dial_data2$Subject==curr_subj & 
                                            wrangle_dial_data2$Block==curr_blk &
                                            wrangle_dial_data2$Trial==curr_trl &
                                            wrangle_dial_data2$Session=="rand")] <- rand_pos
          
          check <- rbind(check, data.frame("subj" = curr_subj, "blk" = curr_blk, "trl" = curr_trl, "cond" = "struct","ord" = I(list(as.integer(pos_order[1:3])))))
          check <- rbind(check, data.frame("subj" = curr_subj, "blk" = curr_blk, "trl" = curr_trl, "cond" = "rand","ord" = I(list(as.integer(rand_pos[1:3])))))
                               
        } else {
          # return the condition that's missing
          # setdiff(c("struct","rand"),unique(curr_subset$Session))
          # We know that struct is missing from both s1504 and h1209's dataset. For these two, copy the pattern for the unmatched random trials from the first     block. 
          print(curr_subj, curr_blk, curr_trl)
          pos_order <-  wrangle_dial_data2 %>% dplyr::filter(Subject==curr_subj,Block==1,Trial==curr_trl) %>% dplyr::filter(Session=="struct") %>% pull(Position) %>% .[1:3]
          rand_pos <- rep_len(pos_order,length(which(curr_subset$Session=="rand")))
          wrangle_dial_data2$Position[which(wrangle_dial_data2$Subject==curr_subj & 
                                            wrangle_dial_data2$Block==curr_blk &
                                            wrangle_dial_data2$Trial==curr_trl &
                                            wrangle_dial_data2$Session=="rand")] <- rand_pos} 
    } 
  } 
}

```


## b. Create Pseudo Time Index (Replace later with actual timepoints...)
```{r}
# dplyr::filter for each Trial, in each Block, in each Subject, and number the elements in pairs of 3 (all dials at once)
wrangle_dial_data2 <- wrangle_dial_data2 %>%
  mutate(X = 0)

for (curr_subj in 1:n_subjs_dial) {
  curr_dial_subj <- wrangle_dial_data2[which(wrangle_dial_data2$Subject==subj_IDs_dial[curr_subj]),]
  for (curr_blk in 1:max(curr_dial_subj$Block)) {
  curr_dial_subj_blk <- curr_dial_subj[which(curr_dial_subj$Block==curr_blk),]
    for (curr_trl in 1:max(curr_dial_subj_blk$Trial)) {
    curr_dial_subj_blk_trl <- curr_dial_subj_blk[which(curr_dial_subj_blk$Trial==curr_trl),]
    
    rem = mod(nrow(curr_dial_subj_blk_trl),3)
    n_xs = ((nrow(curr_dial_subj_blk_trl)-rem)/3)
    X = c(rep(1:n_xs,each=3),rep(n_xs+1,rem))
    curr_dial_subj_blk_trl$X = X
    
    curr_dial_subj_blk[which(curr_dial_subj_blk$Trial==curr_trl),] <- curr_dial_subj_blk_trl
    } 
  curr_dial_subj[which(curr_dial_subj$Block==curr_blk),] <- curr_dial_subj_blk
  } 
wrangle_dial_data2[which(wrangle_dial_data2$Subject==subj_IDs_dial[curr_subj]),] <- curr_dial_subj
}


dial_data <- wrangle_dial_data2

write.csv(dial_data,file.path(data_path_save,"exp_4_dial_data.csv"), row.names = FALSE)

```
Note that all subjects should have 60 Trials (3 (Blocks) x 10 (Trials) x 2 (Conditions)) x 18 (Subjects) + 
2 subjects who have incomplete data sets... 
h1209's random is complete. Their struct has until B2:T8. (30+18 = 48 Trials)
s1504's random is complete. Their struct has until B2:T1. (30+11 = 41 Trials)
Total Trials = 1,169

## c. Subset Starting Points/End Points
```{r}
# Take the first 3 values from the top of each trial 
starting_points_data <- subset(dial_data, FALSE)
ending_points_data <- subset(dial_data, FALSE)

# Logic: go through each subject, block, trial, AND SESSION, and sample the first/last three values, which will feature the starting values (dials 1, 2, and 3) in some order. 
for (curr_subj in 1:n_subjs_dial) {
  curr_dial_subj <- dial_data[which(dial_data$Subject==subj_IDs_dial[curr_subj]),]
  for (curr_blk in 1:max(curr_dial_subj$Block)) {
  curr_dial_subj_blk <- curr_dial_subj[which(curr_dial_subj$Block==curr_blk),]
    for (curr_trl in 1:max(curr_dial_subj_blk$Trial)) {
    curr_dial_subj_blk_trl <- curr_dial_subj_blk[which(curr_dial_subj_blk$Trial==curr_trl),]
      for (curr_sess in c("struct","rand")) {
      curr_dial_subj_blk_trl_sess <- curr_dial_subj_blk_trl[which(curr_dial_subj_blk_trl$Session==curr_sess),]
        starting_points_data <- bind_rows(starting_points_data,head(curr_dial_subj_blk_trl_sess,n=3))
      } 
    } 
  } 
}

starting_points_data$Point <- as.factor(rep("start",nrow(starting_points_data)))

for (curr_subj in 1:n_subjs_dial) {
  curr_dial_subj <- dial_data[which(dial_data$Subject==subj_IDs_dial[curr_subj]),]
  for (curr_blk in 1:max(curr_dial_subj$Block)) {
  curr_dial_subj_blk <- curr_dial_subj[which(curr_dial_subj$Block==curr_blk),]
    for (curr_trl in 1:max(curr_dial_subj_blk$Trial)) {
    curr_dial_subj_blk_trl <- curr_dial_subj_blk[which(curr_dial_subj_blk$Trial==curr_trl),]
      for (curr_sess in c("struct","rand")) {
      curr_dial_subj_blk_trl_sess <- curr_dial_subj_blk_trl[which(curr_dial_subj_blk_trl$Session==curr_sess),]
        ending_points_data <- bind_rows(ending_points_data,tail(curr_dial_subj_blk_trl_sess,n=3))
      } 
    } 
  } 
}
ending_points_data$Point <- as.factor(rep("end",nrow(ending_points_data)))

dial_points_data <- bind_rows(starting_points_data,ending_points_data) %>%
  mutate(Cond_Order = as.factor(Cond_Order),
         Point = as.factor(Point))


write.csv(dial_points_data,file.path(data_path_save,"exp_4_dial_points_data.csv"), row.names = FALSE)
```


# -- PLANNED BASIC ANALYSES -- 
# 2. Summary Stats
```{r}
dial_points_data %>%
      summarySE(measurevar="Curr_ISI", groupvars=c("Session","Position","Point"), na.rm=TRUE)

```

## 2a. Summarize Dial Start, End
```{r}
dial_start_sum1 <- starting_points_data %>%
    summarySE(measurevar="Curr_ISI", groupvars=c("Session","Dial"), na.rm=TRUE)
dial_start_sum2 <- starting_points_data %>%
    summarySE(measurevar="Curr_ISI", groupvars=c("Dial"), na.rm=TRUE)
dial_end_sum1 <- ending_points_data %>%
    summarySE(measurevar="Curr_ISI", groupvars=c("Session","Dial"), na.rm=TRUE)
dial_end_sum2 <- ending_points_data %>%
    summarySE(measurevar="Curr_ISI", groupvars=c("Dial"), na.rm=TRUE)

```

## 2b. Summarize Position Start, End
```{r}
pos_start_sum1 <- starting_points_data %>%
    summarySE(measurevar="Curr_ISI", groupvars=c("Session","Position"), na.rm=TRUE)
pos_start_sum2 <- starting_points_data %>%
    summarySE(measurevar="Curr_ISI", groupvars=c("Position"), na.rm=TRUE)
pos_end_sum1 <- ending_points_data %>%
    summarySE(measurevar="Curr_ISI", groupvars=c("Session","Position"), na.rm=TRUE)
pos_end_sum2 <- ending_points_data %>%
    summarySE(measurevar="Curr_ISI", groupvars=c("Position"), na.rm=TRUE)

```


# 3. Plot Start/End
## a. Control: Plot Dial Facets
```{r}
# Starts
ggplot(starting_points_data, aes(x = Dial, y = Curr_ISI, fill = Dial, colour = Dial)) +
  geom_flat_violin(position = position_nudge(x = .25, y = 0), adjust = 2) +
  geom_point(position = position_jitter(width = .15), size = .25) +
  geom_point(data = dial_start_sum1, aes(x = Dial, y = Curr_ISI_mean), 
             position = position_nudge(.25), colour = "BLACK") +
  geom_errorbar(data = dial_start_sum1, aes(x = Dial, y = Curr_ISI_mean, 
                                       ymin = Curr_ISI_mean-se, ymax = Curr_ISI_mean+se), 
                position = position_nudge(.25), colour = "BLACK", width = 0.1, size = 0.8) +
  facet_grid(. ~ Session) +
  # axes
  scale_x_discrete(name="Dials") + # scale x 
  scale_y_continuous(name="Interval (msec.)",limits=c(0,700)) + # scale y
  scale_fill_manual(values=c("#01665e","#5ab4ac","#c7eae5")) +
  scale_color_manual(values=c("#01665e","#5ab4ac","#c7eae5")) +
  guides(fill=FALSE,color=FALSE) +
  # theme
  theme_minimal() +
  theme(text = element_text(family = "LM Roman 10", face="bold")) + 
  ggtitle("Starting ISIs") + 
  ggsave(file.path(res_path,'figures','exp4_dials_starts.png'), width = w, height = h+1)

# Ends
ggplot(ending_points_data, aes(x = Dial, y = Curr_ISI, fill = Dial, colour = Dial)) +
  geom_flat_violin(position = position_nudge(x = .25, y = 0), adjust = 2) +
  geom_point(position = position_jitter(width = .15), size = .25) +
  geom_point(data = dial_end_sum1, aes(x = Dial, y = Curr_ISI_mean), 
             position = position_nudge(.25), colour = "BLACK") +
  geom_errorbar(data = dial_end_sum1, aes(x = Dial, y = Curr_ISI_mean, 
                                       ymin = Curr_ISI_mean-se, ymax = Curr_ISI_mean+se), 
                position = position_nudge(.25), colour = "BLACK", width = 0.1, size = 0.8) +
  facet_grid(. ~ Session) +
  # axes
  scale_x_discrete(name="Dials") + # scale x 
  scale_y_continuous(name="Interval (msec.)",limits=c(0,700)) + # scale y
  scale_fill_manual(values=c("#01665e","#5ab4ac","#c7eae5")) +
  scale_color_manual(values=c("#01665e","#5ab4ac","#c7eae5")) +
  guides(fill=FALSE,color=FALSE) +
  # theme
  theme_minimal() +
  theme(text = element_text(family = "LM Roman 10", face="bold")) + 
  ggtitle("Ending ISIs") + 
  ggsave(file.path(res_path,'figures','exp4_dials_ends.png'), width = w, height = h+1)
```

## b. Test: Plot Position Facets
```{r}
# Starts
ggplot(starting_points_data, aes(x = Position, y = Curr_ISI, fill = Position, colour = Position)) +
  geom_flat_violin(position = position_nudge(x = .25, y = 0), adjust = 2) +
  geom_point(position = position_jitter(width = .15), size = .25) +
  geom_point(data = pos_start_sum1, aes(x = Position, y = Curr_ISI_mean), 
             position = position_nudge(.25), colour = "BLACK") +
  geom_errorbar(data = pos_start_sum1, aes(x = Position, y = Curr_ISI_mean, 
                                       ymin = Curr_ISI_mean-se, ymax = Curr_ISI_mean+se), 
                position = position_nudge(.25), colour = "BLACK", width = 0.1, size = 0.8) +
  geom_line(data = pos_start_sum1, aes(x = Position, y = Curr_ISI_mean, group = 1), 
             position = position_nudge(.25), colour = "BLACK") +
  facet_grid(. ~ Session) +
  # axes
  scale_x_discrete(name="Gaps") + # scale x 
  scale_y_continuous(name="Interval (msec.)",limits=c(0,700)) + # scale y
  scale_fill_manual(values=wes_palette("Darjeeling1")[c(4,3,2)]) +
  scale_color_manual(values=wes_palette("Darjeeling1")[c(4,3,2)]) +
  guides(fill=FALSE,color=FALSE) +
  # theme
  theme_minimal() +
  theme(text = element_text(family = "LM Roman 10", face="bold")) + 
  ggtitle("Starting ISIs") + 
  ggsave(file.path(res_path,'figures','exp4_gaps_starts.png'), width = w, height = h+1)

# Ends
ggplot(ending_points_data, aes(x = Position, y = Curr_ISI, fill = Position, colour = Position)) +
  geom_flat_violin(position = position_nudge(x = .25, y = 0), adjust = 2) +
  geom_point(position = position_jitter(width = .15), size = .25) +
  geom_point(data = pos_end_sum1, aes(x = Position, y = Curr_ISI_mean), 
             position = position_nudge(.25), colour = "BLACK") +
  geom_errorbar(data = pos_end_sum1, aes(x = Position, y = Curr_ISI_mean, 
                                       ymin = Curr_ISI_mean-se, ymax = Curr_ISI_mean+se), 
                position = position_nudge(.25), colour = "BLACK", width = 0.1, size = 0.8) +
  geom_line(data = pos_end_sum1, aes(x = Position, y = Curr_ISI_mean, group = 1), 
             position = position_nudge(.25), colour = "BLACK") +
  facet_grid(. ~ Session) +
  # axes
  scale_x_discrete(name="Gaps") + # scale x 
  scale_y_continuous(name="Interval (msec.)",limits=c(0,700)) + # scale y
  scale_fill_manual(values=wes_palette("Darjeeling1")[c(4,3,2)]) +
  scale_color_manual(values=wes_palette("Darjeeling1")[c(4,3,2)]) +
  guides(fill=FALSE,color=FALSE) +
  #coord_cartesian(ylim=c(100,300)) +
  # theme
  theme_minimal() +
  theme(text = element_text(family = "LM Roman 10", face="bold")) + 
  ggtitle("Ending ISIs") + 
  ggsave(file.path(res_path,'figures','exp4_gaps_ends.png'), width = w, height = h+1)
```

#4. Plot Trajectories Data 
## Summarize
```{r}
dial_traject_position_sum1 <- dial_data %>%
    summarySE(measurevar="Curr_ISI", groupvars=c("Session","Position","X","Subject"), na.rm=TRUE)

# Align data sets to their ends, and plot that way...
# Source: https://stackoverflow.com/questions/27766054/getting-the-top-values-by-group
pos_traj_sorted <- dial_traject_position_sum1 %>% 
  arrange(Subject, Session, Position, X = desc(X)) %>%
  group_by(Subject,Session,Position) %>%
  slice(1:40) # Take the last 20 data points

# Now reassign the X arrays... [could also wait to do this when we have the timing data]
pos_traj_sorted <- pos_traj_sorted %>%
  group_by(Subject,Session,Position) %>%
  dplyr::mutate(X = row_number()) # Could also try rowid_to_column())



```

## a. Test: Plot Gap Trajectories 
```{r}
ggplot(pos_traj_sorted, mapping=aes(desc(X),Curr_ISI_mean,fill=Position, colour=Position)) +
  #geom_point(size=1) +
 # geom_line(aes(group=Subject,fill=Subject)) + 
  geom_smooth(aes(group=Position,colour=Position),se=TRUE,size=1) +
  
  facet_wrap(.~ Session) +

  scale_y_continuous(name="Interval (msec)") + 
  #scale_x_discrete(name="Gaps") + # scale x 
  scale_y_continuous(name="Interval (msec.)",limits=c(0,700)) + # scale y
  scale_fill_manual(values=wes_palette("Darjeeling1")[c(4,3,2)]) +
  scale_color_manual(values=wes_palette("Darjeeling1")[c(4,3,2)]) +
  theme_minimal() +
  theme(text = element_text(family = "LM Roman 10", face="bold")) #+
#  ggsave('ia_dial_traj.png',width=w,height=h+1)


```
This is collapesd over subjects and trials and only the last 40 data points were taken. 

# 5. Distribution Fitting
Task: Find the right distribution, to then be able to run your models accurately. 

Data is:
- continuous
- positive
- zero-inflated (where zeros may or may not be informative, but are not indicators of true negative values)

In fact, it is likely not the case that all the values clustered at 0 and at 600 were intentional, 
they rather probably didn't figure it out and left the dials at an extreme setting. 

Define: significance level at 0.05

```{r}
library(MASS)
library(fitdistrplus)

# Add column that converts 0s to 1's... 
#dial_points_data$Curr_ISI_0[which(dial_points_data$Curr_ISI==0)] <- 1

ending_ISIs <- ending_points_data$Curr_ISI
descdist(ending_ISIs, discrete = FALSE,boot=800)
#uniform and beta dist's are  candidates
# fit.uni  <- fitdist(ending_ISIs, "uniform")
# fit.beta<- fitdist(ending_ISIs, "beta")
# summary(fit.uni)
# summary(fit.beta)
```


```{r}
# require(car)
# require(MASS)
# require(extraDistr)
# require(gamlss.dist)
# require(zoo)
# # See great table of entire distribution options in R: https://cran.r-project.org/web/views/Distributions.html
# 
# # Data including IV, DV, and a set of values between those (in time), where it's tricky to determine the influence of the IV-Starting-ISI vs. IV-Position, etc.
# hist(dial_data$Curr_ISI, breaks=100)
# 
# # Independent Variable [of no Interest]: 
# hist(starting_points_data$Curr_ISI, breaks=100) 
# # H1: Follows a random distribution
# 
# #### Dependent Variable of Interest:  ####
# hist(ending_points_data$Curr_ISI, breaks=100)
# # H0: Follows a random distribution
# x <- ending_points_data$Curr_ISI
# 
# # Normal? 
# qqp(x,"norm") # No. 
# 
# # Log normal? 
# qqp(x,"lnorm")
# 
# # Pass data to candidate distribution & run test 
# (px <- hist(x,breaks=10)) # bins
# 
# num_of_samples = 100000
# 
# # Chi Squared Test on bucketized hist output (counts) & Kolmogorovâ€“Smirnov test
# # Source for testing goodness of fit: https://www.r-bloggers.com/goodness-of-fit-test-in-r/
# 
# 
#   # 1. Beta Distribution with peaks at the tails
#   hist(y.beta <- rbeta(length(x),shape1 = 0.1, shape2 = 0.1))
#   
#   beta.cdf <- pbeta(px$breaks, 0.1, 0.1)
#   pbeta.null <- rollapply(beta.cdf, 2, function(x) x[2]-x[1]) 
#         # Since the primary distribution and samples are bucketized, we need to do the same thing 
#         # for the reference distribution. In other words, for reference Gamma distribution we need 
#         # to calculate the probability of each bucket. We can use the above piece of code to do that.
#   
#   # Something about this doesn't work... 
#   (beta.test <- chisq.test(px$counts, p=as.double(pbeta.null), rescale.p=TRUE, simulate.p.value=TRUE))
#   (beta.test <- chisq.test(x, p=as.double(y.beta), rescale.p=TRUE, simulate.p.value=TRUE))
# 
# # chisq.test(x, p=as.double(y.beta), rescale.p=TRUE, simulate.p.value=TRUE)
# # 
# # 	Chi-squared test for given probabilities with simulated p-value (based on 2000 replicates)
# # 
# # data:  x
# # X-squared = 2.677e+40, df = NA, p-value = 0.0004998
#   
#   # But this test fails. Not the same dist. 
#     ks.test(x, y.beta)
#   
#     #Zero-Inflated Beta
#     hist(y.beta0 <- rBEZI(num_of_samples,0.5,0.1))
#     
#     # Also fails, but this looks most similar... 
#     ks.test(x, y.beta0)
# 
#   # 2. Gamma / Inverse Gaussian
#   hist(y.gamma <- rgamma(num_of_samples, shape = 0.5, scale = 70))
# 
#   ks.test(x, y.gamma)
#   ks.test(x[which(x<600)],y.gamma)
  
  # Source: https://stats.stackexchange.com/questions/190763/how-to-decide-which-glm-family-to-use
  # NB: For glmer, both Gamma and inverse.gaussian with the standard link function return errors, because only positive values are allowed. 

  # 3. Poisson
  # Some indications of Poisson being theoretically valid..., the zero-inflated normal Poisson for continuous data with points at zero
  # Source: https://stats.stackexchange.com/questions/303514/family-in-glm-how-to-choose-the-right-one

# Or, relabel all 0's to 1's. Then we are saying that the minimum ISI was 1 ms, which we can say is theoretically indifferentiable from 1, especially given the physical constraints of the experiment


```

#6. GLMMs

## a. All data points/trajectory
Begin with the main manipulation of interest. 

Question 1: Is there a three-way interaction between Position, Point & Session? Specifically, does the Curr_ISI_mean at the END increase with each POS, exclusively (or at least more so) in SESS-STRUCT than it does in SESS-RAND? 

```{r}

# glm.dd.1a <- glmer(Curr_ISI ~ Position + (1 | Cond_Order/Subject), data = dplyr::filter(dial_points_data,Session=="struct"), family = Gamma)
#   summary(glm.dd.1a)
#   plot(glm.dd.1a)
#   qqnorm(resid(glm.dd.1a))
#   Anova(glm.dd.1a)
#   
# glm.dd.1b <- glmer(Curr_ISI ~ Position*Session + (1 | Cond_Order/Subject), data = dplyr::filter(dial_points_data,Session=="struct"), family = "beta")
#   summary(glm.dd.1b)
#   plot(glm.dd.1b)
#   qqnorm(resid(glm.dd.1b))
#   Anova(glm.dd.1b)
#   
# anova(glm.dd.1a,glm.dd.1b)
```


```{r}

# glm.dd.1c <- glmer(Curr_ISI ~ Position*Point*Session*Cond_Order + (1 | Cond_Order/Subject), data = dial_points_data, family = poisson)
#   summary(glm.dd.1c)
#   plot(glm.dd.1c)
#   qqnorm(resid(glm.dd.1c))
#   Anova(glm.dd.1c)
# 
# glm.dd.1d <- glmer(Curr_ISI ~ Position*Point*Session*Block + (1 | Cond_Order/Subject), data = dial_points_data, family = poisson)
#   summary(glm.dd.1d)
#   plot(glm.dd.1d)
#   qqnorm(resid(glm.dd.1d))
#   Anova(glm.dd.1d)
# 
# anova(glm.dd.1c,glm.dd.1d)



```

## b. Ending Points Data
```{r}
# glm.dd.2 <- glmer(Curr_ISI ~ Position*Session*Block + (1 | Cond_Order/Subject), data = ending_points_data, family = poisson)
#   summary(glm.dd.2)
#   plot(glm.dd.2)
#   qqnorm(resid(glm.dd.2))
#   Anova(glm.dd.2)
#   
# glm.dd.2b <- glmer(Curr_ISI ~ Position*Session + (1 | Cond_Order/Subject), data = ending_points_data, family = poisson)
#   summary(glm.dd.2b)
#   plot(glm.dd.2b)
#   qqnorm(resid(glm.dd.2b))
#   Anova(glm.dd.2b)  
#   
# glm.dd.2c <- glmer(Curr_ISI ~ Position + (1 | Cond_Order/Subject), data = ending_points_data, family = poisson)
#   summary(glm.dd.2c)
#   plot(glm.dd.2c)
#   qqnorm(resid(glm.dd.2c))
#   Anova(glm.dd.2c)  
#   
#   anova(glm.dd.2,glm.dd.2b,glm.dd.2c)
  
```


# MID-PROCEDURE EVAL. 

Now that we have run some preliminary summary statistics (#2) and plotted the basic data (#3), and observed that our task elicited some unexpected behavior (see #3 and also #5 for histograms -- there are many extreme values where participant-selected ISIs occured at the extremes of 0 and 600 msecs). This demands a more systematic exploration of the data in order to determine any systematic sources of noise or variability that we might need to account for. We wil proceed as follows: 

1- Determine where (in which subjects) and when (block/trials) the 0,600 values occur. With LM, we decided we may exclude trials in which all values are (i) the same & (ii) at the extremes. Additionally, if these two conditions hold & (iii) subjects fail to explore the dynamic range of the dial (there's little to no variability in each trial in a given block), the block may be removed. 

2- Ending values will be normalized within each cell (trial) in order to eliminate differences in scale when comparing the mean difference between gaps in ISIs. We will also normalize within blocks in order to have an N of 30 for a better sampling. These two will both be presented and analyzed. The one that will be selected for interpretation, if they are different, will be the block-level normalization, as this entails a normalization over a larger sample, hence more robust to measurement bias. 

3- As per David's suggestion, we will remove 0's and 600's to see if this helps clear up data. AK's Response (30/4/20): this may not be an optimal strategy. The reason is that it is unclear what percentage of those 0's and 600's are mistakes or meaningful data points (e.g. it is possible that participants intended to select those values). Furthermore, these two tails are differentially theoretically meaningful. Because the temporal interval between the stimuli in the exposure phase was 35 ms, and the common period of human speech is in the 200-300 ms range, it is likely that the true intended value of participants' gap determination is closer to 0 than to 600. (In fact, in retrospect it was likely suboptimal to have the gap range extend very far past 400 ms.) Thus, it seems more likely that some 0's were intentional than that some 600's were. 

Moreover, removing all 0's and 600's leaves many trials incomplete, as it may result in dropping one of the three gap data points, thus rending that cell somewhat inadequate for analysis. We have therefore decided to include those values where the other gap values are neither 0 nor 600, and to exlude trials where all three are at the extremes. In addition, participants who systematically select those extreme and uniform values as end points may have not understood the instructions or failed to comply. This would result in a removal of the block, if more than half ended so. 

# -- EXPLORATORY ANALYSES/GET TO KNOW DATA THEN RERUN PLANNED ANALYSES -- 

#1. Normalization on End Points
```{r}
require(jmotif)
# NB: You may need to rerun Chunk 6! 

# v1: Remove 0s and 600's
# v2: Remove as per item (3) above
ending_points_data_filt <- ending_points_data #%>%
  #dplyr::filter(Curr_ISI < 600 & Curr_ISI > 0)

# WITH 0S & 600S
ending_points_data <- ending_points_data %>%
      add_column(Z_normed = rep(NA,length(ending_points_data$Curr_ISI)), .after = "Curr_ISI") %>%
      add_column(Mu_normed = rep(NA,length(ending_points_data$Curr_ISI)), .after = "Z_normed") 
      
      
# Mean & Z-normalization
for (curr_subj in 1:n_subjs_dial) {
  curr_dial_subj <- ending_points_data[which(ending_points_data$Subject==subj_IDs_dial[curr_subj]),]
  for (curr_blk in 1:max(curr_dial_subj$Block)) {
  curr_dial_subj_blk <- curr_dial_subj[which(curr_dial_subj$Block==curr_blk),]
    for (curr_trl in 1:max(curr_dial_subj_blk$Trial)) {
    curr_dial_subj_blk_trl <- curr_dial_subj_blk[which(curr_dial_subj_blk$Trial==curr_trl),]
      for (curr_sess in c("struct","rand")) {
        
      curr_dial_subj_blk_trl_sess <- curr_dial_subj_blk_trl[which(curr_dial_subj_blk_trl$Session==curr_sess),]
        subgroup_mean <- mean(curr_dial_subj_blk_trl_sess$Curr_ISI)
        mean_normed <- curr_dial_subj_blk_trl_sess$Curr_ISI-subgroup_mean
        z_normed <- znorm(curr_dial_subj_blk_trl_sess$Curr_ISI)
        
        curr_dial_subj_blk_trl_sess$Z_normed <- z_normed
        curr_dial_subj_blk_trl_sess$Mu_normed <- mean_normed

    curr_dial_subj_blk_trl[which(curr_dial_subj_blk_trl$Session==curr_sess),] <- curr_dial_subj_blk_trl_sess
      } 
   curr_dial_subj_blk[which(curr_dial_subj_blk$Trial==curr_trl),] <- curr_dial_subj_blk_trl
    } 
  curr_dial_subj[which(curr_dial_subj$Block==curr_blk),] <- curr_dial_subj_blk
  } 
ending_points_data[which(ending_points_data$Subject==subj_IDs_dial[curr_subj]),] <- curr_dial_subj
}

hist(ending_points_data$Z_normed,breaks = 100)



```

## Normalization and filtering 0's and 600's 
```{r}
# WITHOUT CERTAIN 0'S AND 600'S | ex-WITHOUT 0's and 600's
ending_points_data_filt <- ending_points_data_filt %>%
      add_column(Z_normed = rep(NA,length(ending_points_data_filt$Curr_ISI)), .after = "Curr_ISI") %>%
      add_column(Mu_normed = rep(NA,length(ending_points_data_filt$Curr_ISI)), .after = "Z_normed") 

# table for catching clustered data/participants
clustered_at_extremes <- data.frame(subj = factor(), sess = factor(), block = integer(), trial = integer(), type = double())


      
# Mean & Z-normalization
for (curr_subj in 1:n_subjs_dial) {
  curr_dial_subj <- ending_points_data_filt[which(ending_points_data_filt$Subject==subj_IDs_dial[curr_subj]),]
  for (curr_blk in 1:max(curr_dial_subj$Block)) {
  curr_dial_subj_blk <- curr_dial_subj[which(curr_dial_subj$Block==curr_blk),]
    for (curr_trl in 1:max(curr_dial_subj_blk$Trial)) {
    curr_dial_subj_blk_trl <- curr_dial_subj_blk[which(curr_dial_subj_blk$Trial==curr_trl),]
      for (curr_sess in c("struct","rand")) {
        
      curr_dial_subj_blk_trl_sess <- curr_dial_subj_blk_trl[which(curr_dial_subj_blk_trl$Session==curr_sess),]
      
      # if they're the same and at the extremes 
      if (length(unique(curr_dial_subj_blk_trl_sess$Curr_ISI))==1 &
          (all(curr_dial_subj_blk_trl_sess$Curr_ISI == 600) | all(curr_dial_subj_blk_trl_sess$Curr_ISI == 0))) { # change this to any if you want to remove them...
        
        clustered_at_extremes <- rbind(clustered_at_extremes, data.frame(
          subj = subj_IDs_dial[curr_subj], sess = curr_sess, block = curr_blk, trial = curr_trl, 
          type = unique(curr_dial_subj_blk_trl_sess$Curr_ISI)))

        curr_dial_subj_blk_trl_sess$Z_normed <- NA
        curr_dial_subj_blk_trl_sess$Mu_normed <- NA
        
          }
      else {        
      
        subgroup_mean <- mean(curr_dial_subj_blk_trl_sess$Curr_ISI)
        mean_normed <- curr_dial_subj_blk_trl_sess$Curr_ISI-subgroup_mean
        z_normed <- znorm(curr_dial_subj_blk_trl_sess$Curr_ISI)
        
        curr_dial_subj_blk_trl_sess$Z_normed <- z_normed
        curr_dial_subj_blk_trl_sess$Mu_normed <- mean_normed
      }
    curr_dial_subj_blk_trl[which(curr_dial_subj_blk_trl$Session==curr_sess),] <- curr_dial_subj_blk_trl_sess
      } 
   curr_dial_subj_blk[which(curr_dial_subj_blk$Trial==curr_trl),] <- curr_dial_subj_blk_trl
    } 
  curr_dial_subj[which(curr_dial_subj$Block==curr_blk),] <- curr_dial_subj_blk
  } 
ending_points_data_filt[which(ending_points_data_filt$Subject==subj_IDs_dial[curr_subj]),] <- curr_dial_subj
}

hist(ending_points_data_filt$Z_normed,breaks = 100)

```

## Getting to know the deviants
```{r}
# TO DO: Check again that tutorial on the clever uses of count()...

length(unique(clustered_at_extremes$subj))

ggplot(data=clustered_at_extremes, aes(trial,fill=as.factor(type))) +
  geom_histogram(binwidth=1) +
  facet_wrap(~block)

```
15 out of 20 subjects generated end point ISIs at 0's and 600's. 
The distributions are roughly equally distributed across (although noisily). There are many more 0's than 600's. 


# Individual trajectories 
```{r}
# ending_points_data
# dial_points_data
require(gganimate)
  
ggplot(dial_data, aes(X, Curr_ISI, fill=Position, colour=Position)) +
  geom_smooth(aes(group = Position)) +
  facet_grid(Session ~ Subject,scales = "free") + 
  scale_y_continuous(name="Interval (msec.)",limits=c(0,700)) + 
  scale_colour_brewer(palette = "Set2") +
  scale_fill_brewer(palette = "Pastel2") +
  #scale_fill_manual(values=c("#01665e","#5ab4ac","#c7eae5")) +
  #scale_color_manual(values=c("#01665e","#5ab4ac","#c7eae5")) +
  #theme_minimal() +
  theme(text = element_text(family = "LM Roman 10", face="bold")) +
  #transition_states(X,transition_length = 1, state_length = 1) +
  #ease_aes('linear')
  ggsave('ia_dial_traj_individ.png',width = 20,height=6)



```




## ai. Replot with Z Norm
```{r}
norm_pos_end_sum1 <- ending_points_data %>%
    summarySE(measurevar="Z_normed", groupvars=c("Session","Position"), na.rm=TRUE)

ggplot(ending_points_data, aes(x = Position, y = Z_normed, fill = Position, colour = Position)) +
  geom_flat_violin(position = position_nudge(x = .25, y = 0), adjust = 2) +
  geom_point(position = position_jitter(width = .15), size = .25) +
  geom_point(data = norm_pos_end_sum1, aes(x = Position, y = Z_normed_mean), 
             position = position_nudge(.25), colour = "BLACK") +
  geom_errorbar(data = norm_pos_end_sum1, aes(x = Position, y = Z_normed_mean, 
                                       ymin = Z_normed_mean-se, ymax = Z_normed_mean+se), 
                position = position_nudge(.25), colour = "BLACK", width = 0.1, size = 0.8) +
  geom_line(data = norm_pos_end_sum1, aes(x = Position, y = Z_normed_mean, group = 1), 
             position = position_nudge(.25), colour = "BLACK") +
  facet_grid(. ~ Session) +
  # axes
  scale_x_discrete(name="Gaps") + # scale x 
 # scale_y_continuous(name="Interval (msec.)",limits=c(0,700)) + # scale y
  scale_fill_manual(values=c("#01665e","#5ab4ac","#c7eae5")) +
  scale_color_manual(values=c("#01665e","#5ab4ac","#c7eae5")) +
  guides(fill=FALSE,color=FALSE) +
  #coord_cartesian(ylim=c(100,300)) +
  # theme
  theme_minimal() +
  theme(text = element_text(family = "LM Roman 10", face="bold")) + 
  ggtitle("Ending ISIs") + 
  ggsave('ia_DV_ending_isi_rainclouds_facets_ZNORM.png', width = w, height = h+1)
```

## aii. Replot with Z Norm - filtered
```{r}
# Without

norm_pos_end_filt_sum1 <- ending_points_data_filt %>%
    summarySE(measurevar="Z_normed", groupvars=c("Session","Position"), na.rm=TRUE)


# With
ggplot(ending_points_data_filt, aes(x = Position, y = Z_normed, fill = Position, colour = Position)) +
  geom_flat_violin(position = position_nudge(x = .25, y = 0), adjust = 2) +
  geom_point(position = position_jitter(width = .15), size = .25) +
  geom_point(data = norm_pos_end_filt_sum1, aes(x = Position, y = Z_normed_mean), 
             position = position_nudge(.25), colour = "BLACK") +
  geom_errorbar(data = norm_pos_end_filt_sum1, aes(x = Position, y = Z_normed_mean, 
                                       ymin = Z_normed_mean-se, ymax = Z_normed_mean+se), 
                position = position_nudge(.25), colour = "BLACK", width = 0.1, size = 0.8) +
  geom_line(data = norm_pos_end_filt_sum1, aes(x = Position, y = Z_normed_mean, group = 1), 
             position = position_nudge(.25), colour = "BLACK") +
  facet_grid(. ~ Session) +
  # axes
  scale_x_discrete(name="Gaps") + # scale x 
 # scale_y_continuous(name="Interval (msec.)",limits=c(0,700)) + # scale y
  scale_fill_manual(values=c("#01665e","#5ab4ac","#c7eae5")) +
  scale_color_manual(values=c("#01665e","#5ab4ac","#c7eae5")) +
  guides(fill=FALSE,color=FALSE) +
 coord_cartesian(ylim=c(-2,2)) +
  # theme
  theme_minimal() +
  theme(text = element_text(family = "LM Roman 10", face="bold")) + 
  ggtitle("Ending ISIs") + 
  ggsave('ia_DV_ending_isi_rainclouds_facets_ZNORM_filt.png', width = w, height = h+1)


ending_points_data_filt$Curr_ISI %>% count()
norm_pos_end_filt_sum1$Z_normed_mean
```

#### with Mean Norm - filtered
```{r}
norm_pos_end_filt_sum2 <- ending_points_data_filt %>%
    summarySE(measurevar="Mu_normed", groupvars=c("Session","Position"), na.rm=TRUE)

# With
ggplot(ending_points_data_filt, aes(x = Position, y = Mu_normed, fill = Position, colour = Position)) +
  geom_flat_violin(position = position_nudge(x = .25, y = 0), adjust = 2) +
  geom_point(position = position_jitter(width = .15), size = .25) +
  geom_point(data = norm_pos_end_filt_sum2, aes(x = Position, y = Mu_normed_mean), 
             position = position_nudge(.25), colour = "BLACK") +
  geom_errorbar(data = norm_pos_end_filt_sum2, aes(x = Position, y = Mu_normed_mean, 
                                       ymin = Mu_normed_mean-se, ymax = Mu_normed_mean+se), 
                position = position_nudge(.25), colour = "BLACK", width = 0.1, size = 0.8) +
  geom_line(data = norm_pos_end_filt_sum2, aes(x = Position, y = Mu_normed_mean, group = 1), 
             position = position_nudge(.25), colour = "BLACK") +
  facet_grid(. ~ Session) +
  # axes
  scale_x_discrete(name="Gaps") + # scale x 
 # scale_y_continuous(name="Interval (msec.)",limits=c(0,700)) + # scale y
  scale_fill_manual(values=c("#01665e","#5ab4ac","#c7eae5")) +
  scale_color_manual(values=c("#01665e","#5ab4ac","#c7eae5")) +
  guides(fill=FALSE,color=FALSE) +
  #coord_cartesian(ylim=c(-2,2)) +
  # theme
  theme_minimal() +
  theme(text = element_text(family = "LM Roman 10", face="bold")) + 
  ggtitle("Ending ISIs")

```


## Re-GLMM
Once you decide on a dplyr::filtering strategy, return here. 
```{r}
descdist(ending_points_data$Mu_normed, discrete = FALSE,boot=800)

hist(ending_points_data_filt$Mu_normed, breaks = 100)



fit.norm  <- fitdist(ending_points_data$Mu_normed[!is.na(ending_points_data$Mu_normed)], "norm")
fit.log <- fitdist(ending_points_data$Mu_normed[!is.na(ending_points_data$Mu_normed)], "logistic")
summary(fit.wei)
summary(fit.gam)
summary(fit.ln)

par(mfrow=c(2,2))
plot.legend <- c("Weibull", "lognormal", "gamma")
denscomp(list(fit.wei, fit.gam, fit.ln), legendtext = plot.legend)
cdfcomp (list(fit.wei, fit.gam, fit.ln), legendtext = plot.legend)
qqcomp  (list(fit.wei, fit.gam, fit.ln), legendtext = plot.legend)
ppcomp  (list(fit.wei, fit.gam, fit.ln), legendtext = plot.legend)

gofstat(list(fit.wei, fit.gam, fit.ln), fitnames = c("weibull", "gamma", "lognorm"))



z.mod.full <- glmer(Curr_ISI ~ Session * Position * Block + (1 | Cond_Order/Subject), data = ending_points_data_filt, family = Gamma)


```




